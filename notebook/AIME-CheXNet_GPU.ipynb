{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest versions\n",
    "path = kagglehub.dataset_download(\"nih-chest-xrays/sample\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# ダウンロードされたデータセットのパス\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# データがzipファイルの場合、解凍します\n",
    "if path.endswith(\".zip\"):\n",
    "    with zipfile.ZipFile(path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"nih_chest_xrays\")  # 解凍先のフォルダを指定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# 追加：再現性のためのユーティリティと設定\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tfms\n",
    "import torchvision.transforms.functional as T\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.models import densenet121\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def set_seed_everything(seed: int, deterministic: bool = True):\n",
    "    \"\"\"全ライブラリの乱数を固定し、必要に応じて決定論的アルゴリズムを使用する。\"\"\"\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    # 完全決定論性が必要な場合のみ有効化（環境により非対応Opで例外が出る可能性あり）\n",
    "    # torch.use_deterministic_algorithms(True)\n",
    "    # os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    \"\"\"DataLoader worker 用のシード初期化。\"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "# DataLoader / random_split で共有する乱数生成器\n",
    "TORCH_GENERATOR = torch.Generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    CLASS_NAMES = [\n",
    "        \"Atelectasis\",\n",
    "        \"Cardiomegaly\",\n",
    "        \"Effusion\",\n",
    "        \"Infiltration\",\n",
    "        \"Mass\",\n",
    "        \"Nodule\",\n",
    "        \"Pneumonia\",\n",
    "        \"Pneumothorax\",\n",
    "        \"Consolidation\",\n",
    "        \"Edema\",\n",
    "        \"Emphysema\",\n",
    "        \"Fibrosis\",\n",
    "        \"Pleural_Thickening\",\n",
    "        \"Hernia\",\n",
    "    ]\n",
    "    BASE_PATH = Path(\n",
    "        \"/home/kosukeyano/.cache/kagglehub/datasets/nih-chest-xrays/sample/versions/4/sample\"\n",
    "    )\n",
    "    BEST_MODEL_PATH = \"models/best_model.pt\"\n",
    "    EPOCHS = 20\n",
    "    DEVICE = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    INTERVAL = 10\n",
    "    # 追加：再現性\n",
    "    SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数の固定を適用\n",
    "set_seed_everything(CFG.SEED, deterministic=True)\n",
    "# random_split / DataLoader で用いる Generator にもシードを設定\n",
    "TORCH_GENERATOR.manual_seed(CFG.SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CFG.BASE_PATH / \"sample_labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元のコード（比較用）\n",
    "# df = df[[\"Image Index\", \"Finding Labels\"]]\n",
    "# 修正：列選択は.locで行い、後続で編集するのでcopy()で独立させる\n",
    "df = df.loc[:, [\"Image Index\", \"Finding Labels\"]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make paths absolute\n",
    "# 元のコード（比較用）\n",
    "# df[\"Image Index\"] = [\n",
    "#     CFG.BASE_PATH / f\"images/{path}\" for path in df[\"Image Index\"].values\n",
    "# ]\n",
    "# Remove \"No Finding\"\n",
    "# 元のコード（比較用）\n",
    "# df = df[df[\"Finding Labels\"].isin([\"No Finding\"]) == False]\n",
    "\n",
    "# 修正：列代入は.locで明示\n",
    "df.loc[:, \"Image Index\"] = [\n",
    "    CFG.BASE_PATH / f\"images/{path}\" for path in df[\"Image Index\"].values\n",
    "]\n",
    "# 修正：ブールインデックス後はcopy()で独立\n",
    "mask = ~df[\"Finding Labels\"].isin([\"No Finding\"])\n",
    "df = df.loc[mask].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(shape=(len(df), 14))\n",
    "for idx, lab in tqdm(enumerate(df[\"Finding Labels\"].values), total=len(df)):\n",
    "    lbls = lab.split(\"|\")\n",
    "    lbl_arr = np.zeros(len(CFG.CLASS_NAMES))\n",
    "    for l in lbls:\n",
    "        lbl_arr[CFG.CLASS_NAMES.index(l)] = 1\n",
    "    labels[idx] = lbl_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {k: v for k, v in zip(CFG.CLASS_NAMES, labels.transpose())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元のコード（比較用）\n",
    "# for k, v in d.items():\n",
    "#     df[k] = v\n",
    "\n",
    "# 修正案1：列名リストを作り、一括代入（最も高速で明確）\n",
    "cols = list(d.keys())\n",
    "values = np.column_stack([d[k] for k in cols])\n",
    "df.loc[:, cols] = values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(df, rows, columns, figsize=(20, 20)):\n",
    "    \"\"\"\n",
    "    Function to plot images\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(rows, columns, figsize=figsize)\n",
    "    fig.subplots_adjust(hspace=0.01, wspace=0.1)\n",
    "    idx = 1\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            image = np.asarray(Image.open(df[\"Image Index\"].values[idx]).convert(\"RGB\"))\n",
    "            labels = df[\"Finding Labels\"].values[idx].split(\"|\")\n",
    "            axs[i, j].imshow(image)\n",
    "            axs[i, j].yaxis.set_visible(False)\n",
    "            axs[i, j].set_xticklabels([])\n",
    "            axs[i, j].set_xlabel(labels)\n",
    "            idx += 1\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./final.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(df, 2, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXNetData(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.df[\"Image Index\"].values[idx]).convert(\"RGB\")\n",
    "        label = self.df.iloc[:, 2:].values[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.asarray(image))[\"image\"]\n",
    "\n",
    "        label = torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose(transforms=[A.Normalize(), ToTensorV2()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = CheXNetData(df=df, transform=transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = ds[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(ds)\n",
    "train_len = int(0.8 * total)\n",
    "val_len = total - train_len\n",
    "\n",
    "# 元のコード（比較用）\n",
    "# train_ds, test_ds = random_split(dataset=ds, lengths=[train_len, val_len])\n",
    "# 修正：Generator を指定して分割を再現可能に\n",
    "train_ds, test_ds = random_split(\n",
    "    dataset=ds, lengths=[train_len, val_len], generator=TORCH_GENERATOR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(train_ds)\n",
    "train_len = int(0.8 * total)\n",
    "val_len = total - train_len\n",
    "\n",
    "# 元のコード（比較用）\n",
    "# train_ds, val_ds = random_split(dataset=train_ds, lengths=[train_len, val_len])\n",
    "# 修正：こちらも Generator を指定\n",
    "train_ds, val_ds = random_split(\n",
    "    dataset=train_ds, lengths=[train_len, val_len], generator=TORCH_GENERATOR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The lengths of train, val and test dataset: {len(train_ds)} images, {len(val_ds)} images, and {len(test_ds)} images\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = {\n",
    "    \"train\": len(train_ds),\n",
    "    \"val\": len(val_ds),\n",
    "    \"test\": len(test_ds),\n",
    "}  # Size dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元のコード（比較用）\n",
    "# loaders = {\n",
    "#     \"train\": DataLoader(train_ds, batch_size=8, shuffle=True),\n",
    "#     \"val\": DataLoader(val_ds, batch_size=4),\n",
    "#     \"test\": DataLoader(test_ds, batch_size=4),\n",
    "# }\n",
    "\n",
    "# 修正：Generator を渡し、worker_init_fn で worker 側の乱数も固定\n",
    "loaders = {\n",
    "    \"train\": DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=8,\n",
    "        shuffle=True,\n",
    "        generator=TORCH_GENERATOR,\n",
    "        worker_init_fn=seed_worker,\n",
    "    ),\n",
    "    \"val\": DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        generator=TORCH_GENERATOR,\n",
    "        worker_init_fn=seed_worker,\n",
    "    ),\n",
    "    \"test\": DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        generator=TORCH_GENERATOR,\n",
    "        worker_init_fn=seed_worker,\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(DenseNet121, self).__init__()\n",
    "\n",
    "        # 元のコード（比較用）\n",
    "        # self.densenet121 = densenet121(pretrained=True)\n",
    "        # 修正：weights引数を使用\n",
    "        from torchvision.models import DenseNet121_Weights\n",
    "\n",
    "        self.densenet121 = densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)\n",
    "        n_features = self.densenet121.classifier.in_features\n",
    "        self.densenet121.classifier = nn.Sequential(\n",
    "            nn.Linear(n_features, n_classes), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_batches = {k: len(v) for k, v in loaders.items()}\n",
    "ds_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check is models folder exists\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "\n",
    "# Set up logger\n",
    "logging.basicConfig(\n",
    "    filename=\"train.log\",\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    filemode=\"w\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元のコード（比較用）\n",
    "# def calc_mean_auc(labels: torch.tensor, preds: torch.tensor):\n",
    "#     labels = labels.cpu().detach().numpy()\n",
    "#     preds = preds.cpu().detach().numpy()\n",
    "#\n",
    "#     per_class_AUROC = []\n",
    "#     for i, name in enumerate(CFG.CLASS_NAMES):\n",
    "#         try:\n",
    "#             per_class_AUROC.append(roc_auc_score(labels[:, i], preds[:, i]))\n",
    "#         except ValueError:\n",
    "#             pass\n",
    "#     mean_roc_auc = np.array(per_class_AUROC).mean()\n",
    "#\n",
    "#     return mean_roc_auc\n",
    "\n",
    "# 修正：単一クラス（全て0または全て1）の場合はスキップ\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "def calc_mean_auc(labels: torch.tensor, preds: torch.tensor):\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "\n",
    "    per_class_AUROC = []\n",
    "    for i, name in enumerate(CFG.CLASS_NAMES):\n",
    "        y_true = labels[:, i]\n",
    "        y_score = preds[:, i]\n",
    "        # y_trueに0/1の両方が含まれていなければAUCは未定義\n",
    "        if len(np.unique(y_true)) < 2:\n",
    "            continue\n",
    "        per_class_AUROC.append(roc_auc_score(y_true, y_score))\n",
    "\n",
    "    # 有効クラスが無ければNaNを返す\n",
    "    if len(per_class_AUROC) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    mean_roc_auc = np.array(per_class_AUROC).mean()\n",
    "    return mean_roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_AUROC = 0.0  # Global AUROC\n",
    "\n",
    "\n",
    "def run_one_epoch(\n",
    "    epoch: int,\n",
    "    ds_sizes: Dict[str, int],\n",
    "    dataloaders: Dict[str, DataLoader],\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss: nn.Module,\n",
    "    scheduler: torch.optim.lr_scheduler,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run one complete train-val loop\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "\n",
    "    ds_sizes: Dictionary containing dataset sizes\n",
    "    dataloaders: Dictionary containing dataloaders\n",
    "    model: The model\n",
    "    optimizer: The optimizer\n",
    "    loss: The loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    metrics: Dictionary containing metrics\n",
    "\n",
    "    \"\"\"\n",
    "    global best_AUROC\n",
    "\n",
    "    metrics = {}\n",
    "    AUROCs = []\n",
    "\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        logging.info(f\"{phase.upper()} phase\")\n",
    "\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        avg_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(\n",
    "            tqdm(dataloaders[phase], total=len(dataloaders[phase]))\n",
    "        ):\n",
    "\n",
    "            images = images.to(CFG.DEVICE)\n",
    "            labels = labels.to(CFG.DEVICE)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Track history if in phase == \"train\"\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Calculate AUROC\n",
    "                auroc = calc_mean_auc(labels, outputs)\n",
    "                AUROCs.append(auroc)\n",
    "\n",
    "            avg_loss += loss.item() * images.size(0)\n",
    "\n",
    "            if batch_idx % CFG.INTERVAL == 0:\n",
    "                logging.info(\n",
    "                    f\"Epoch {epoch} - {phase.upper()} - Batch {batch_idx} - Loss = {round(loss.item(), 3)} | AUROC = {round(auroc, 3)}\"\n",
    "                )\n",
    "\n",
    "        epoch_loss = avg_loss / ds_sizes[phase]\n",
    "        epoch_val_mean = np.array(AUROCs).mean()\n",
    "\n",
    "        # step the scheduler\n",
    "        if phase == \"train\":\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        # save best model wts\n",
    "        if phase == \"val\" and epoch_val_mean > best_AUROC:\n",
    "            best_AUROC = epoch_val_mean\n",
    "            best_model_wts = deepcopy(model.state_dict())\n",
    "            timestampTime = time.strftime(\"%H%M%S\")\n",
    "            timestampDate = time.strftime(\"%d%m%Y\")\n",
    "            timestampEND = timestampDate + \"-\" + timestampTime\n",
    "            best_model_path = f\"models/CheXNet-{timestampEND}.pt\"\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"val_loss\": epoch_loss,\n",
    "                    \"val_AUROC\": epoch_val_mean,\n",
    "                    \"model\": best_model_wts,\n",
    "                },\n",
    "                best_model_path,\n",
    "            )\n",
    "\n",
    "        # Metrics tracking\n",
    "        if phase == \"train\":\n",
    "            metrics[\"train_loss\"] = round(epoch_loss, 3)\n",
    "        else:\n",
    "            metrics[\"val_loss\"] = round(epoch_loss, 3)\n",
    "            metrics[\"val_mean_AUROC\"] = round(epoch_val_mean, 3)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloaders, ds_sizes, model, optimizer, criterion, scheduler):\n",
    "    table = PrettyTable(\n",
    "        field_names=[\"Epoch\", \"Train Loss\", \"Val Loss\", \"Val Mean AUROC\"]\n",
    "    )\n",
    "\n",
    "    for epoch in range(CFG.EPOCHS):\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        metrics = run_one_epoch(\n",
    "            epoch=epoch,\n",
    "            ds_sizes=ds_sizes,\n",
    "            dataloaders=dataloaders,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            loss=criterion,\n",
    "            scheduler=scheduler,\n",
    "        )\n",
    "\n",
    "        end = time.time() - start\n",
    "\n",
    "        print(f\"Epoch completed in: {round(end/60, 3)} mins\")\n",
    "\n",
    "        table.add_row(\n",
    "            row=[\n",
    "                epoch + 1,\n",
    "                metrics[\"train_loss\"],\n",
    "                metrics[\"val_loss\"],\n",
    "                metrics[\"val_mean_AUROC\"],\n",
    "            ]\n",
    "        )\n",
    "        print(table)\n",
    "\n",
    "    # Write results to file\n",
    "    with open(\"results.txt\", \"w\") as f:\n",
    "        results = table.get_string()\n",
    "        f.write(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet121(n_classes=14).to(CFG.DEVICE)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=1e-4)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, mode=\"min\", patience=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train(\n",
    "#     dataloaders=loaders,\n",
    "#     ds_sizes=ds_size,\n",
    "#     model=model,\n",
    "#     optimizer=optimizer,\n",
    "#     criterion=criterion,\n",
    "#     scheduler=scheduler,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, hamming_loss\n",
    "\n",
    "# 保存したモデルをロードしてテストセットで評価\n",
    "saved_model_path = (\n",
    "    \"/home/kosukeyano/workspace/huber_aime/notebook/models/CheXNet-10092025-173011.pt\"\n",
    ")\n",
    "\n",
    "model_loaded = DenseNet121(n_classes=len(CFG.CLASS_NAMES)).to(CFG.DEVICE)\n",
    "# 元のコード（比較用）\n",
    "# state_dict = torch.load(saved_model_path, map_location=CFG.DEVICE)\n",
    "# model_loaded.load_state_dict(state_dict)\n",
    "\n",
    "# 修正: PyTorch 2.6以降の安全ロードに対応（trusted checkpoint）\n",
    "checkpoint = torch.load(saved_model_path, map_location=CFG.DEVICE, weights_only=False)\n",
    "# 互換処理: 'model'キーにstate_dictがある形式と、state_dictのみの両方に対応\n",
    "state_dict = (\n",
    "    checkpoint[\"model\"]\n",
    "    if isinstance(checkpoint, dict) and \"model\" in checkpoint\n",
    "    else checkpoint\n",
    ")\n",
    "model_loaded.load_state_dict(state_dict)\n",
    "model_loaded.eval()\n",
    "\n",
    "out_gt_test_loaded = torch.FloatTensor()\n",
    "out_pred_test_loaded = torch.FloatTensor()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(loaders[\"test\"]):\n",
    "        images = images.to(CFG.DEVICE)\n",
    "        labels = labels.to(CFG.DEVICE)\n",
    "        outputs = model_loaded(images)\n",
    "        outputs = outputs.cpu().detach()\n",
    "        out_gt_test_loaded = torch.cat((out_gt_test_loaded, labels.cpu().detach()), 0)\n",
    "        out_pred_test_loaded = torch.cat((out_pred_test_loaded, outputs.data), 0)\n",
    "\n",
    "labels_test_loaded = out_gt_test_loaded.numpy()\n",
    "preds_test_loaded = out_pred_test_loaded.numpy()\n",
    "\n",
    "# しきい値で2値化（マルチラベル）\n",
    "preds_bin = (preds_test_loaded >= 0.5).astype(int)\n",
    "\n",
    "# 指標の算出\n",
    "subset_acc = accuracy_score(labels_test_loaded, preds_bin)\n",
    "micro_f1 = f1_score(labels_test_loaded, preds_bin, average=\"micro\", zero_division=0)\n",
    "macro_f1 = f1_score(labels_test_loaded, preds_bin, average=\"macro\", zero_division=0)\n",
    "hamming = hamming_loss(labels_test_loaded, preds_bin)\n",
    "\n",
    "# AUROCは有効クラスのみで算出（単一クラスはcalc_mean_auc内でスキップ）\n",
    "mean_auroc = calc_mean_auc(\n",
    "    torch.tensor(labels_test_loaded), torch.tensor(preds_test_loaded)\n",
    ")\n",
    "\n",
    "print(f\"Subset accuracy: {subset_acc:.3f}\")\n",
    "print(f\"Micro F1: {micro_f1:.3f}\")\n",
    "print(f\"Macro F1: {macro_f1:.3f}\")\n",
    "print(f\"Hamming loss: {hamming:.3f}\")\n",
    "print(f\"Mean AUROC (valid classes only): {mean_auroc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_train = []  # 入力画像を保存するリスト\n",
    "with torch.no_grad():\n",
    "    # model.eval()\n",
    "    model_loaded.eval()\n",
    "    out_gt_train = torch.FloatTensor()\n",
    "    out_pred_train = torch.FloatTensor()\n",
    "    for images, labels in tqdm(loaders[\"train\"]):\n",
    "        all_images_train.append(images)\n",
    "        images_train = images.to(CFG.DEVICE)\n",
    "        labels_train = labels.to(CFG.DEVICE)\n",
    "\n",
    "        # outputs = model(images_train)\n",
    "        outputs = model_loaded(images_train)\n",
    "        outputs = outputs.cpu().detach()\n",
    "\n",
    "        out_gt_train = torch.cat((out_gt_train, labels_train.cpu().detach()), 0)\n",
    "        out_pred_train = torch.cat((out_pred_train, outputs.data), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_test = []  # 入力画像を保存するリスト\n",
    "with torch.no_grad():\n",
    "    # model.eval()\n",
    "    model_loaded.eval()\n",
    "    out_gt_test = torch.FloatTensor()\n",
    "    out_pred_test = torch.FloatTensor()\n",
    "    for images, labels in tqdm(loaders[\"test\"]):\n",
    "        all_images_test.append(images)\n",
    "        images_test = images.to(CFG.DEVICE)\n",
    "        labels_test = labels.to(CFG.DEVICE)\n",
    "\n",
    "        # outputs = model(images_test)\n",
    "        outputs = model_loaded(images_test)\n",
    "        outputs = outputs.cpu().detach()\n",
    "\n",
    "        out_gt_test = torch.cat((out_gt_test, labels_test.cpu().detach()), 0)\n",
    "        out_pred_test = torch.cat((out_pred_test, outputs.data), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_train_tensor = torch.cat(all_images_train, dim=0)\n",
    "print(\"All images train shape:\", all_images_train_tensor.shape)\n",
    "all_images_test_tensor = torch.cat(all_images_test, dim=0)\n",
    "print(\"All images test shape:\", all_images_test_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# # 元のコード（比較用）\n",
    "# # # RGB画像をグレースケールに変換するためのTransform\n",
    "# # to_grayscale = transforms.Grayscale(num_output_channels=1)\n",
    "# #\n",
    "# # # 画像をグレースケールに変換\n",
    "# # all_images_train_tensor_gray = to_grayscale(all_images_train_tensor)\n",
    "# # all_images_test_tensor_gray = to_grayscale(all_images_test_tensor)\n",
    "\n",
    "# # 修正：RGBのままダウンサンプリングしてAIME用に準備\n",
    "# AIME_IMAGE_SIZE = 1024\n",
    "# all_images_train_tensor_resized = F.interpolate(\n",
    "#     all_images_train_tensor,\n",
    "#     size=(AIME_IMAGE_SIZE, AIME_IMAGE_SIZE),\n",
    "#     mode=\"bilinear\",\n",
    "#     align_corners=False,\n",
    "# )\n",
    "# all_images_test_tensor_resized = F.interpolate(\n",
    "#     all_images_test_tensor,\n",
    "#     size=(AIME_IMAGE_SIZE, AIME_IMAGE_SIZE),\n",
    "#     mode=\"bilinear\",\n",
    "#     align_corners=False,\n",
    "# )\n",
    "\n",
    "# print(all_images_train_tensor.shape)\n",
    "# print(all_images_test_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 元のコード（比較用）\n",
    "# X_train = all_images_train_tensor_gray.reshape(1639, 1 * 1024 * 1024)\n",
    "# X_test = all_images_test_tensor_gray.reshape(513, 1 * 1024 * 1024)\n",
    "\n",
    "# 修正：RGB (C=3) × AIME_IMAGE_SIZE × AIME_IMAGE_SIZE に合わせてフラット化\n",
    "N_train = all_images_train_tensor.shape[0]\n",
    "N_test = all_images_test_tensor.shape[0]\n",
    "C, H, W = all_images_train_tensor.shape[1:]\n",
    "X_train = all_images_train_tensor.reshape(N_train, C * H * W)\n",
    "X_test = all_images_test_tensor.reshape(N_test, C * H * W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = out_gt_train.numpy()\n",
    "preds_train = out_pred_train.numpy()\n",
    "labels_test = out_gt_test.numpy()\n",
    "preds_test = out_pred_test.numpy()\n",
    "\n",
    "per_class_AUROC = []\n",
    "\n",
    "print(\"-----PER - CLASS AUROC------\")\n",
    "\n",
    "# 元のコード（比較用）\n",
    "# for i, name in enumerate(CFG.CLASS_NAMES):\n",
    "#     try:\n",
    "#         print(\n",
    "#             f\"{name} - {round(roc_auc_score(labels_test[:, i], preds_test[:, i]), 3)}\"\n",
    "#         )\n",
    "#     except ValueError:\n",
    "#         pass\n",
    "# mean_roc_auc = np.array(per_class_AUROC).mean()\n",
    "\n",
    "# 修正：単一クラス（全て0 or 全て1）はスキップして明示的に表示\n",
    "for i, name in enumerate(CFG.CLASS_NAMES):\n",
    "    y_true = labels_test[:, i]\n",
    "    y_score = preds_test[:, i]\n",
    "    if len(np.unique(y_true)) < 2:\n",
    "        print(f\"{name} - skipped (only one class in y_true)\")\n",
    "        continue\n",
    "    print(f\"{name} - {round(roc_auc_score(y_true, y_score), 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import cupy as cp\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"/home/kosukeyano/workspace/huber_aime\" not in sys.path:\n",
    "    sys.path.append(\"/home/kosukeyano/workspace/huber_aime\")\n",
    "\n",
    "from aime_xai.core import AIME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = preds_train\n",
    "y_hat_test = preds_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_hat_train.shape)\n",
    "print(y_hat_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aime = AIME()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化のためのスケーラーを作成\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# 元のコード（比較用）\n",
    "# X_test_scaled = scaler.fit_transform(X_test)\n",
    "# 修正：テストは学習スケーラーで変換のみ\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_cpu = time.time()\n",
    "aime.create_explainer(X_train_scaled, y_hat_train, normalize=False)\n",
    "end_cpu = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end_cpu - start_cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled = cp.array(X_train_scaled, dtype=cp.float32)\n",
    "# y_hat_train = cp.array(y_hat_train, dtype=cp.float32)\n",
    "# # AIMEのExplainerを作成\n",
    "\n",
    "# torch.cuda.synchronize()\n",
    "# start_gpu = time.time()\n",
    "# aime_gpu.create_explainer(X_train_scaled, y_hat_train, normalize=False)\n",
    "# cp.cuda.Stream.null.synchronize()  # GPU計算が終わるのを待つ\n",
    "# end_gpu = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aime.A_dagger.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [f\"pixel_{i}\" for i in range(X_train.shape[1])]\n",
    "class_names = [\n",
    "    \"Atelectasis\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Effusion\",\n",
    "    \"Infiltration\",\n",
    "    \"Mass\",\n",
    "    \"Nodule\",\n",
    "    \"Pneumonia\",\n",
    "    \"Pneumothorax\",\n",
    "    \"Consolidation\",\n",
    "    \"Edema\",\n",
    "    \"Emphysema\",\n",
    "    \"Fibrosis\",\n",
    "    \"Pleural_Thickening\",\n",
    "    \"Hernia\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グローバル特徴重要度の計算と可視化\n",
    "df_global_importance = aime.global_feature_importance(\n",
    "    feature_names=feature_names, class_names=class_names, top_k=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB向け可視化ユーティリティ（AIME_for_ImageDataを参考）\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_signed_2d(img3, mode=\"maxabs\", clip_pct=99.5):\n",
    "    \"\"\"\n",
    "    img3: (H,W,3) の寄与マップ (局所/大域 いずれも可)\n",
    "    mode: \"l2\" | \"maxabs\"\n",
    "        - \"l2\"    : 符号=優勢チャネルの符号、値=L2ノルム\n",
    "        - \"maxabs\": 符号=優勢チャネルの符号、値=max(|R|,|G|,|B|)\n",
    "    clip_pct: 上位パーセンタイルで外れ値をクリップして[-1,1]に正規化\n",
    "    return: [-1,1] 正規化の 2D マップ\n",
    "    \"\"\"\n",
    "    C = img3.astype(np.float32)\n",
    "    absC = np.abs(C)\n",
    "    dom_idx = np.argmax(absC, axis=2)\n",
    "\n",
    "    if mode == \"l2\":\n",
    "        mag = np.sqrt((C**2).sum(axis=2))\n",
    "    elif mode == \"maxabs\":\n",
    "        mag = absC.max(axis=2)\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'l2' or 'maxabs'\")\n",
    "\n",
    "    sign = np.take_along_axis(np.sign(C), dom_idx[..., None], axis=2).squeeze(2)\n",
    "    signed = sign * mag\n",
    "\n",
    "    vmax = np.percentile(np.abs(signed), clip_pct) + 1e-12\n",
    "    signed = np.clip(signed, -vmax, vmax) / vmax\n",
    "    return signed\n",
    "\n",
    "\n",
    "def show_global_signed(w_c3, title, fname=None, mode=\"maxabs\"):\n",
    "    signed2d = compute_signed_2d(w_c3, mode=mode)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(\n",
    "        signed2d, cmap=\"inferno\", norm=mcolors.TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1)\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout()\n",
    "    if fname:\n",
    "        plt.savefig(fname, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def show_local_with_original(\n",
    "    orig_img3, contrib_img3, true_name, fname=None, mode=\"maxabs\"\n",
    "):\n",
    "    signed2d = compute_signed_2d(contrib_img3, mode=mode)\n",
    "    fig, axes = plt.subplots(\n",
    "        1,\n",
    "        3,\n",
    "        figsize=(9, 4),\n",
    "        gridspec_kw={\"width_ratios\": [1, 1, 0.05]},\n",
    "    )\n",
    "    ax0, ax1, cax = axes\n",
    "    ax0.imshow(orig_img3)\n",
    "    ax0.set_title(f\"Original (true={true_name})\")\n",
    "    ax0.axis(\"off\")\n",
    "    im = ax1.imshow(\n",
    "        signed2d, cmap=\"inferno\", norm=mcolors.TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1)\n",
    "    )\n",
    "    ax1.set_title(f\"Local Importance ({mode}, signed)\")\n",
    "    ax1.axis(\"off\")\n",
    "    fig.colorbar(im, cax=cax)\n",
    "    plt.subplots_adjust(wspace=0.02)\n",
    "    if fname:\n",
    "        plt.savefig(fname, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グローバルな特徴重要度のデータフレームを取得（RGB対応）\n",
    "df_global = aime.global_feature_importance_without_viz(\n",
    "    feature_names=feature_names, class_names=class_names\n",
    ")\n",
    "# DataFrameを取得\n",
    "df_global = df_global.to_pandas() if hasattr(df_global, \"to_pandas\") else df_global\n",
    "\n",
    "# 可視化設定\n",
    "rows, cols = 2, 7\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(25, 10))\n",
    "\n",
    "# 各クラスごとに (H,W,3) へ整形し、RGB集約（符号付き）で表示\n",
    "for idx, class_label in enumerate(class_names):\n",
    "    w_c = df_global.loc[class_label].values  # 長さ = 3*H*W\n",
    "    H = W = 1024\n",
    "    w_c3 = w_c.reshape(3, H, W).transpose(1, 2, 0)  # (H,W,3)\n",
    "\n",
    "    ax = axes[idx // cols, idx % cols]\n",
    "    signed2d = compute_signed_2d(w_c3, mode=\"maxabs\")\n",
    "    im = ax.imshow(\n",
    "        signed2d,\n",
    "        cmap=\"inferno\",\n",
    "        norm=mcolors.TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1),\n",
    "    )\n",
    "    ax.set_title(f\"{class_label}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "fig.tight_layout()\n",
    "# 代表imからカラーバーを作成\n",
    "cbar = fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.6)\n",
    "cbar.set_label(\"Signed Feature Importance (RGB aggregated)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカル特徴重要度の計算と可視化\n",
    "index = 1\n",
    "# サンプルのインデックス\n",
    "x_sample = X_train_scaled[index]\n",
    "y_sample = y_hat_train[index]\n",
    "original_label = labels_train[index]\n",
    "\n",
    "# ローカル特徴重要度の計算\n",
    "df_local_importance = aime.local_feature_importance_without_viz(\n",
    "    x_sample,\n",
    "    y_sample,\n",
    "    feature_names=feature_names,\n",
    "    scale=True,\n",
    "    scaler=scaler,\n",
    "    ignore_zero_features=True,\n",
    ")\n",
    "\n",
    "# ローカル重要度（RGB対応）\n",
    "H = W = 1024\n",
    "# 局所寄与ベクトル (3*H*W) を (H,W,3) に整形\n",
    "importance_local = df_local_importance.values.reshape(3, H, W).transpose(1, 2, 0)\n",
    "\n",
    "original_class_index = original_label.argmax()  # 配列内で1の位置を取得\n",
    "original_class = class_names[original_class_index]\n",
    "\n",
    "# 元画像（学習時の正規化を逆変換して0-1へ）\n",
    "orig = all_images_train_tensor[index].cpu().numpy().transpose(1, 2, 0)\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "orig_img3 = np.clip(orig * imagenet_std + imagenet_mean, 0, 1)\n",
    "\n",
    "# 可視化（符号付きRGB集約）\n",
    "show_local_with_original(\n",
    "    orig_img3=orig_img3,\n",
    "    contrib_img3=importance_local,\n",
    "    true_name=original_class,\n",
    "    fname=None,\n",
    "    mode=\"maxabs\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
